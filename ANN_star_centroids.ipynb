{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_star_centroids.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzIjRL6TKYYN"
      },
      "source": [
        "Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd6p35Q2qhPJ"
      },
      "source": [
        "!pip install h5py\n",
        "!pip install xarray\n",
        "!pip install h5netcdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQdpyqnlKBeX"
      },
      "source": [
        "#OLD_50 \n",
        "#поставь большой ОЗУ\n",
        "\n",
        "#https://drive.google.com/file/d/1Db7Np1-AYMhJhXThqFoHpqL0sxJseneU/view?usp=sharing\n",
        "!gdown --id 1Db7Np1-AYMhJhXThqFoHpqL0sxJseneU\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!unzip gaia.zip\n",
        "!rm -rf 'gaia.zip'\n",
        "\n",
        "\n",
        "#clear_output()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaTFR5RJztrY"
      },
      "source": [
        "!pip uninstall opencv-python-headless \n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!pip install -U albumentations\n",
        "clear_output()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim\n",
        "import torch.profiler\n",
        "import torch.utils.data\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as I\n",
        "\n",
        "from osgeo import gdal\n",
        "import sys\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "\n",
        "import os, shutil\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "import xarray as xr\n",
        "\n",
        "#Фиксируем random_seed\n",
        "import random\n",
        "import numpy as np\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "#Выставлям device для расчетов\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-hjbrcVFHP2"
      },
      "source": [
        "Создаем класс датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7JVq_UB27wR"
      },
      "source": [
        "def set_taper(im , coords, shape, taper=0.3):\n",
        "\n",
        "    window1d = np.abs(np.blackman(shape))\n",
        "    window2d = np.sqrt(np.outer(window1d,window1d))\n",
        "\n",
        "    window2d = np.where(window2d>taper, taper, window2d)\n",
        "    window2d = window2d/np.max(window2d)\n",
        "    windownew = np.zeros((shape, shape))\n",
        "\n",
        "    coords = np.round(coords)\n",
        "    a,b = int(coords[0,1]), int(coords[0,0])\n",
        "    dx = a-int(shape/2)\n",
        "    dy = b-int(shape/2)\n",
        "    x_new = range(0,shape-abs(dx)) if dx<0 else range(dx,shape)\n",
        "    x_old = range(abs(dx),shape) if dx<0 else range( 0,shape-dx)\n",
        "\n",
        "    if dy<0:\n",
        "      windownew[ x_new  , 0:shape-abs(dy)] = window2d[x_old, abs(dy):shape ]\n",
        "    else:\n",
        "      windownew[ x_new  ,dy:shape] = window2d[x_old, 0:shape-dy ]\n",
        "\n",
        "    return  np.multiply(im, windownew)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDrDEDptwnND"
      },
      "source": [
        "import sys\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "\n",
        "def get_mask(coords , shape, isG, g_sigma, precision=1):\n",
        "    if precision != 0:\n",
        "        mask = np.zeros((shape*(precision*10),shape*(precision*10)))\n",
        "        coords = np.round(coords,precision)*(precision*10)\n",
        "        coords = np.array( coords, dtype = np.uint8)\n",
        "        coords = coords[coords[:,0]!=0 ]\n",
        "        coords = coords[coords[:,1]!=0 ]\n",
        "        coords = np.where(coords==shape*10, coords-10, coords)\n",
        "        mask[coords[:,1],coords[:,0]] = 1 \n",
        "        if isG:\n",
        "            mask = gaussian_filter(mask, sigma= g_sigma)\n",
        "            mask /= mask.max()\n",
        "    else:\n",
        "        mask = np.zeros((shape,shape))\n",
        "        coords = np.round(coords)\n",
        "        coords = np.array( coords, dtype = np.uint8)\n",
        "        coords = coords[coords[:,0]!=0 ]\n",
        "        coords = coords[coords[:,1]!=0 ]\n",
        "        coords = np.where(coords==shape, coords-1, coords)\n",
        "        mask[coords[:,1],coords[:,0]] = 1 \n",
        "        if isG:\n",
        "            mask = gaussian_filter(mask, sigma= g_sigma)\n",
        "            mask /= mask.max()\n",
        "    return mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyNwNKygoChZ"
      },
      "source": [
        "class StarDataset(Dataset):\n",
        "  def __init__(self, path_png, isTaper=False, taper=0.3, isGauss = True,\n",
        "               gauss=0.75, prec = 1, transform = None, dset=0):\n",
        "    self.isTaper = isTaper\n",
        "    self.taper = taper\n",
        "    self.isGauss = isGauss\n",
        "    self.gauss = gauss\n",
        "    self.prec = prec\n",
        "    assert self.prec >=0, \"Set correct precision!\"\n",
        "    self.files_png = path_png\n",
        "    self.transform = transform\n",
        "    \n",
        "    \n",
        "    self.coords = np.asarray(xr.open_dataarray((self.files_png).replace('images','coords'), engine=\"h5netcdf\") , dtype = np.float32)\n",
        "    self.len = len(self.coords)\n",
        "    if dset==1:\n",
        "      self.coords = self.coords[:int(self.len/2)]  \n",
        "    if dset==2:\n",
        "      self.coords = self.coords[int(self.len/2):]  \n",
        "    self.im = np.asarray(xr.open_dataarray(self.files_png, engine=\"h5netcdf\") , dtype = np.uint8)\n",
        "    if dset==1:\n",
        "      self.im = self.im[:int(self.len/2)]  \n",
        "    if dset==2:\n",
        "      self.im = self.im[int(self.len/2):]  \n",
        "\n",
        "    print(self.im.shape)\n",
        "    print(self.coords.shape)\n",
        "    index = []\n",
        "    for i in range(len(self.coords)):\n",
        "      if self.coords[i, 1, 0] !=0 and self.coords[i, 1, 1] !=0:\n",
        "          index.append(i)\n",
        "    self.coords = np.delete(self.coords, index, axis=0)\n",
        "    self.im = np.delete(self.im, index, axis=0)\n",
        "    self.len = len(self.coords)\n",
        "  \n",
        "  def check(self):\n",
        "    for f in self.files_png:\n",
        "      try:\n",
        "        self.get_coords(f)\n",
        "      except Exception:\n",
        "        print(f\"File with coords not found for {f}\")\n",
        "\n",
        "\n",
        "  def get_coords(self,f):\n",
        "    coords_file = f.replace('.png','.txt')\n",
        "    coords_file = coords_file.replace('image/','coor/')\n",
        "    coords = np.loadtxt(coords_file)\n",
        "    return coords\n",
        "  \n",
        "\n",
        "  def __getitem__(self, i):\n",
        "\n",
        "    im = self.im[i]\n",
        "    coords = self.coords[i]\n",
        "\n",
        "    if self.transform:\n",
        "      transformed = self.transform(image = im, keypoints = coords) \n",
        "      im = transformed['image']\n",
        "      im = np.moveaxis(im, -1, 0)\n",
        "      im = torch.tensor(im, dtype=torch.float32)\n",
        "      coords =  transformed['keypoints'] \n",
        "      shape = im.T.shape\n",
        "      if self.isTaper:\n",
        "        im = set_taper(im, coords, shape[0], taper = self.taper)\n",
        "      coords  = get_mask(coords , shape[0], self.isGauss, self.gauss, self.prec)\n",
        "      \n",
        "    return im, coords\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Nwj95dtG1h"
      },
      "source": [
        "Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th2ln1AmtYPv"
      },
      "source": [
        "\n",
        "def show_img(img, norm=False, figsize=(4,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    if norm:\n",
        "        img = img / 2 + 0.5 \n",
        "    \n",
        "    npimg = img.numpy()\n",
        "    if norm:\n",
        "        npimg = np.clip(npimg, 0., 1.)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbgO2RUG_SzG"
      },
      "source": [
        "crop_size = 16\n",
        "transform_train = A.Compose([\n",
        "     A.CenterCrop(22, 22),\n",
        "     A.RandomCrop(crop_size, crop_size),\n",
        "     A.Flip(p=0.5),\n",
        "     A.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "], keypoint_params=A.KeypointParams(format='xy'))\n",
        "\n",
        "transform_val = A.Compose([\n",
        "     A.CenterCrop(crop_size, crop_size),\n",
        "     A.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "], keypoint_params=A.KeypointParams(format='xy'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1kUpx9SUqA-"
      },
      "source": [
        "train_set = StarDataset(\"train_images_da50.nc\" , \n",
        "                        isTaper = False, taper = 0.2, \n",
        "                        isGauss = True, gauss = 0.75, \n",
        "                        prec = 1, \n",
        "                        transform=transform_train)\n",
        "val_set = StarDataset(\"val_images_da50.nc\" , \n",
        "                      isTaper = False, taper = 0.2, \n",
        "                      isGauss = True, gauss = 0.75, \n",
        "                      prec = 1, \n",
        "                      transform=transform_val)\n",
        "test_set = StarDataset(\"test_images_da50.nc\" , \n",
        "                      isTaper = False, taper = 0.2, \n",
        "                      isGauss = True, gauss = 0.75, \n",
        "                      prec = 1, \n",
        "                      transform=transform_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDaboPt52jpf"
      },
      "source": [
        "print(len(train_set))\n",
        "print(len(val_set))\n",
        "print(len(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pxq6T_pZRLW"
      },
      "source": [
        "b_s =128\n",
        "train_loader = DataLoader(train_set, batch_size=b_s, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=b_s, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size = b_s, shuffle = False, num_workers =4, pin_memory = True)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY76Lvpu4iBd"
      },
      "source": [
        "%%prun -l 0.1\n",
        "for img, target in train_loader:\n",
        "        print(f'Img size {img.size()}')\n",
        "        print(f'Target size {target.size()}') \n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h30mc0AhtBnA"
      },
      "source": [
        "show_img(torchvision.utils.make_grid(img[:24]), norm=True, figsize=(24,24))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBrKSZz8WE2g"
      },
      "source": [
        "def coordinates_heatmap(data):\n",
        "     heatmap, xedges, yedges = np.histogram2d(data.coords[:, :, 0], data.coords[:, :, 0], bins=100)\n",
        "     extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "     return heatmap, extent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXm5I35GpOCr"
      },
      "source": [
        "indx = 5\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(10,10))\n",
        "ax[0].imshow((img[indx].permute(1,2,0))/ 2 + 0.5)\n",
        "ax[1].imshow(target[indx], vmin=0, vmax=1, cmap=\"Greys\")\n",
        "y,x = torch.where(target[indx] == 1)\n",
        "print(y,x)\n",
        "if train_set.prec != 0:\n",
        "    ax[0].scatter(x/10,y/10, facecolors='white', edgecolors='r', s=5)\n",
        "else:\n",
        "    ax[0].scatter(x,y, facecolors='white', edgecolors='r', s=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pGDh1zMyD9V"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SV2MELRxzmC"
      },
      "source": [
        "#defining the cnn architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, img_size=160):\n",
        "        super(Net, self).__init__()\n",
        "       \n",
        "        #defining maxpool block\n",
        "        self.maxpool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        #defining dropout block\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        #defining second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        \n",
        "        #defining linear output layer\n",
        "        self.fc1 = nn.Linear(3200, img_size**2)\n",
        "        \n",
        "  def forward(self, x):\n",
        "\n",
        "        x = self.maxpool(F.relu(self.conv1(x)))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "\n",
        "        #passing x through linear layer\n",
        "        x = self.fc1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        #returning x\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISpjLhmJXKVx"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MU0gBNTNVXn"
      },
      "source": [
        "!pip install torch_tb_profiler\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thq108z1XQLY"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "# Helper method to run Tensorboard in Colab\n",
        "def reinit_tensorboard(clear_log = True, logs = \"/content/runs\"):\n",
        "  logs_base_dir = logs # Directory for log files\n",
        "  if clear_log:    \n",
        "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
        "    os.makedirs(logs_base_dir, exist_ok=True)\n",
        "  # Colab magic\n",
        "  %reload_ext tensorboard\n",
        "  %tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJcRRHbbHeQ9"
      },
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        \n",
        "        return 1 - dice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ijq_VO4sHmv"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "def get_std(image):\n",
        "    return image.std()\n",
        "\n",
        "def get_max(image,alpha=20,size=10, prec=10):\n",
        "    size *= prec\n",
        "    sigma = get_std(image)\n",
        "    i_out = []\n",
        "    j_out = []\n",
        "    image_temp = copy.deepcopy(image)\n",
        "    while True:\n",
        "        k = np.argmax(image_temp)\n",
        "        j,i = np.unravel_index(k, image_temp.shape)\n",
        "        if(image_temp[j,i] >= sigma*alpha):\n",
        "            i_out.append(i)\n",
        "            j_out.append(j)\n",
        "            x = np.arange(i-size, i+size)\n",
        "            y = np.arange(j-size, j+size)\n",
        "            xv,yv = np.meshgrid(x,y)\n",
        "            image_temp[yv.clip(0,image_temp.shape[0]-1),\n",
        "                                   xv.clip(0,image_temp.shape[1]-1) ] = 0\n",
        "        else:\n",
        "            break\n",
        "    return i_out,j_out\n",
        "\n",
        "def get_range(a, b):\n",
        "   dx = (a[0]-b[0])\n",
        "   dy = (a[1]-b[1])\n",
        "   return (dx*dx+dy*dy)**0.5\n",
        "\n",
        "def get_mean(pred, targ, prec):\n",
        "    mean =0. \n",
        "    k=0\n",
        "    for i in range(len(pred)):\n",
        "      min=1e9\n",
        "      for j in range(len(targ)):\n",
        "        dr = get_range(pred[i], targ[j])\n",
        "        if min>dr:\n",
        "          min=dr\n",
        "      if min<4*prec: \n",
        "        k+=1\n",
        "        mean+=min\n",
        "    return mean, k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vd3p10zObp"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "indx = 0\n",
        "\n",
        "def argmax2d(X):\n",
        "    n, m = X.shape\n",
        "    x_ = torch.ravel(X)\n",
        "    k = torch.argmax(x_)\n",
        "    i, j = k // m, k % m\n",
        "    return i, j\n",
        "\n",
        "def show(model, dataloader, indx=0, thres=0.2, prec = 10):\n",
        "  model.eval()\n",
        "  for image, target in dataloader:\n",
        "    break  \n",
        "  correct = 0\n",
        "  total=0\n",
        "  with torch.no_grad():\n",
        "    image = image.type(torch.FloatTensor)\n",
        "    image = torch.unsqueeze(image[indx], 0)\n",
        "    pred = model(image.to(device))\n",
        "    pred = pred.cpu()\n",
        "    pred = torch.reshape(pred, (-1,  target.size(2),  target.size(2)))\n",
        "    pred_i_out, pred_j_out = get_max(pred[indx],alpha=0.5,size=3, prec=10)\n",
        "    c = np.vstack((pred_i_out, pred_j_out)).T\n",
        "    targ_i_out, targ_j_out = get_max(target[indx],alpha=0.5,size=3, prec=10)\n",
        "    d = np.vstack((targ_i_out, targ_j_out)).T\n",
        "    correct += np.sum(np.array_equal(c,d))\n",
        "    total += len(d)\n",
        "    dr, num = get_mean(c,d, prec)\n",
        "    if num!=0:\n",
        "      dr = dr/num/prec\n",
        "    else:\n",
        "      dr=-1\n",
        "\n",
        "  fig,ax = plt.subplots(ncols=3)\n",
        "  ax[0].imshow((image[indx]/ 2 + 0.5).permute(1,2,0), vmin=0, vmax=1)\n",
        "  ax[1].imshow(torch.sum((image[indx]/ 2 + 0.5).permute(1,2,0),  dim=-1)/3, vmin=0, vmax=1)\n",
        "  y_target,x_target = torch.where(target[indx] == 1)\n",
        "  \n",
        "  ax[2].imshow(pred[indx],cmap='inferno', vmin=0, vmax=1)\n",
        "  y_pred,x_pred = argmax2d(pred[indx])\n",
        "  \n",
        "  ax[0].scatter(x_target/prec,y_target/prec, facecolors='green', edgecolors='white', alpha=0.75)\n",
        "  ax[0].scatter(x_pred/prec,y_pred/prec, facecolors='red', edgecolors='white', alpha=0.75)\n",
        "\n",
        "  ax[1].scatter(x_pred/prec,y_pred/prec, facecolors='red', edgecolors='white', alpha=0.75)\n",
        "  ax[1].scatter(x_target/prec,y_target/prec, facecolors='green', edgecolors='white', alpha=0.75)\n",
        "\n",
        "  ax[2].scatter(x_pred,y_pred, facecolors='red', edgecolors='white', alpha=0.75)\n",
        "  ax[2].scatter(x_target,y_target, facecolors='green', edgecolors='white', alpha=0.75)\n",
        "\n",
        "\n",
        "  ax[0].set_title('Input')\n",
        "  ax[1].set_title('Brightness')\n",
        "  ax[2].set_title('Predicted mask')\n",
        "  fig.suptitle('dr= ' + str(round(dr,2)) + \" pix | correct/total= \" + str(correct) + \"/\" + str(total))\n",
        "  return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwAF_o7G5iu"
      },
      "source": [
        "import copy\n",
        "\n",
        "def validate(model, dataloader, device, part, prec=10):\n",
        "    l = len(dataloader)*part*b_s\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    mean = 0\n",
        "    total_mean = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "          images = images.type(torch.FloatTensor)\n",
        "          pred = model(images.to(device))\n",
        "          pred = pred.to('cpu')\n",
        "          pred = torch.reshape(pred, (-1,  targets.size(2),  targets.size(2)))\n",
        "          for i in range((pred.size(0))):\n",
        "              pred_i_out, pred_j_out = get_max(pred[i],alpha=0.5,size=3, prec=10)\n",
        "              c = np.vstack((pred_i_out, pred_j_out)).T\n",
        "              targ_i_out, targ_j_out = get_max(targets[i],alpha=0.5,size=3, prec=10)\n",
        "              d = np.vstack((targ_i_out, targ_j_out)).T\n",
        "              correct += np.sum(np.array_equal(c,d))\n",
        "              total += len(d)\n",
        "              dr, num = get_mean(c,d, prec)\n",
        "              mean +=dr\n",
        "              total_mean+=num\n",
        "              if total > l: \n",
        "                  break\n",
        "          if total > l: \n",
        "              break\n",
        "    print('Correct stars: %i out of %i' % (correct, total))\n",
        "    if total_mean!=0:\n",
        "      dr = mean/total_mean/prec\n",
        "    else:\n",
        "      dr=-1\n",
        "    return correct/total, dr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGeX77gyX38E"
      },
      "source": [
        "def train(model, comment = \"\", epoch_n = 10, prec = 10):\n",
        "  writer = SummaryWriter(comment)\n",
        "  # Run model on cuda\n",
        "  \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  print('Using device:', device)\n",
        "  torch.cuda.empty_cache()\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = DiceLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr = 3e-4)\n",
        "  best_accuracy = 0\n",
        "  n_epochs = epoch_n\n",
        "  step=0\n",
        "  best_acc = 1e9\n",
        "  for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_i, data in enumerate(train_loader):\n",
        "            # get the input images and their corresponding labels\n",
        "            images = data[0]\n",
        "            key_pts = data[1]\n",
        "            # flatten pts\n",
        "            key_pts = key_pts.view(key_pts.size(0), -1)\n",
        "\n",
        "            key_pts = key_pts.type(torch.FloatTensor)\n",
        "            images = images.type(torch.FloatTensor)\n",
        "            key_pts, images = key_pts.to(device), images.to(device) #Чаще делают вот так\n",
        "           \n",
        "            # forward pass to get outputs\n",
        "            output_pts = model(images)\n",
        "            # calculate the loss between predicted and target keypoints\n",
        "            loss = criterion(output_pts, key_pts)\n",
        "            \n",
        "            # zero the parameter (weight) gradients\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            # backward pass to calculate the weight gradients\n",
        "            loss.backward()\n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "            # print loss statistics\n",
        "            running_loss += loss.item()\n",
        "            if batch_i % 100 == 0:    # print every 10 batches\n",
        "                print('Epoch: {}, Batch: {}/{}, Loss: {}'.format(epoch, batch_i+1, len(train_loader), loss.item()))\n",
        "                running_loss = 0.0\n",
        "                writer.add_scalar('Loss/train_step',loss.item(),step)\n",
        "                writer.flush()\n",
        "            step+=1\n",
        "    writer.add_scalar('Loss/train_epoch',loss.item(),epoch)\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy_train , error_train = validate(model,train_loader,device, 0.0625, prec =prec )\n",
        "    writer.add_scalar('Accuracy/Accuracy_train',accuracy_train,epoch)\n",
        "    writer.add_scalar('Error/Error_train',error_train,epoch)\n",
        "\n",
        "    accuracy_val ,error_val = validate(model,val_loader,device, 1, prec =prec )\n",
        "    writer.add_scalar('Accuracy/Accuracy_val',accuracy_val,epoch)\n",
        "    writer.add_scalar('Error/Error_val',error_val,epoch)\n",
        "\n",
        "    writer.add_figure(\"Images/Images_train\", show(model, train_loader, prec =prec ), epoch)\n",
        "    writer.add_figure(\"Images/Images_validate\", show(model, val_loader, prec =prec ), epoch)\n",
        "     \n",
        "    print(\"Epoch {} Loss {:.5f} Error_train {:.5f} Error_validate {:.5f} \\nAccuracy_train {:.5f} Accuracy_validate {:.5f}\".format(epoch, loss.item(),  error_train, error_val, accuracy_train, accuracy_val))\n",
        "    writer.flush()\n",
        "\n",
        "    \n",
        "    if error_val <best_acc: \n",
        "      best_acc = error_val\n",
        "      namem = \"Gaia\" +str(round(error_val,4))\n",
        "      torch.save(net, \"drive/MyDrive/Star_SuperRes/\" + namem)\n",
        "            \n",
        "  writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHPSlwzFX1Ie"
      },
      "source": [
        "reinit_tensorboard(clear_log=True) # If needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4p6bK09U_1W"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHQst_mvBsEt"
      },
      "source": [
        "#net = torch.load('drive/MyDrive/Star_SuperRes/Gaia0.3184')\n",
        "\n",
        "net = torch.load('drive/MyDrive/Star_SuperRes/Last_Mask_old50_0.5761')\n",
        "#torch.save(net, \"Model_start\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylw-tVNZZNY1"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "prec=10\n",
        "net = Net(img_size=16*prec)\n",
        "torch.cuda.empty_cache()\n",
        "train(net, epoch_n=1000, prec =prec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRUsCAvrDuU-"
      },
      "source": [
        "# Тестируем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBJG8RKKCtNc"
      },
      "source": [
        "\n",
        "def get_range(a, b):\n",
        "   dx = (a[0]-b[0])\n",
        "   dy = (a[1]-b[1])\n",
        "   return (dx*dx+dy*dy)**0.5\n",
        "\n",
        "\n",
        "\n",
        "def get_mean(pred, targ, prec):\n",
        "    mean =0. \n",
        "    k=0\n",
        "    dx, dy = 0,0\n",
        "    x, y = 0,0\n",
        "    for i in range(len(targ)):\n",
        "      min=1e9\n",
        "      for j in range(len(pred)):\n",
        "        dr = get_range(targ[i], pred[j])\n",
        "        if min>dr:\n",
        "          min=dr\n",
        "          dx= abs(targ[i, 0]- pred[j, 0])\n",
        "          dy= abs(targ[i, 1]- pred[j, 1])\n",
        "      if min<4*prec: \n",
        "        k+=1\n",
        "        mean+=min\n",
        "        x, y = dx,dy\n",
        "\n",
        "    return mean, x, y, k\n",
        "\n",
        "\n",
        "def validate(model, dataloader, device, part, prec=10):\n",
        "    l = len(dataloader)*part*b_s\n",
        "    lr=[]\n",
        "    lx=[]\n",
        "    ly=[]\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    mean = 0\n",
        "    meanx = 0\n",
        "    meany = 0\n",
        "    total_mean = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "          images = images.type(torch.FloatTensor)\n",
        "          pred = model(images.to(device))\n",
        "          pred = pred.to('cpu')\n",
        "          pred = torch.reshape(pred, (-1,  targets.size(2),  targets.size(2)))\n",
        "          for i in range((pred.size(0))):\n",
        "              pred_i_out, pred_j_out = get_max(pred[i],alpha=0.5,size=3, prec=prec)\n",
        "              c = np.vstack((pred_i_out, pred_j_out)).T\n",
        "              targ_i_out, targ_j_out = get_max(targets[i],alpha=0.5,size=3, prec=prec)\n",
        "              d = np.vstack((targ_i_out, targ_j_out)).T\n",
        "              correct += np.sum(np.array_equal(c,d))\n",
        "              total += len(d)\n",
        "              dr, dx, dy, num = get_mean(c,d, prec)\n",
        "              lr.append(dr)\n",
        "              lx.append(dx)\n",
        "              ly.append(dy)\n",
        "              mean +=dr\n",
        "              meanx +=dx\n",
        "              meany +=dy\n",
        "              total_mean+=num\n",
        "              if total > l: \n",
        "                  break\n",
        "          if total > l: \n",
        "              break\n",
        "    print('Correct stars: %i out of %i' % (correct, total))\n",
        "    dr = mean/total_mean/prec\n",
        "    dx = meanx/total_mean/prec\n",
        "    dy = meany/total_mean/prec\n",
        "\n",
        "    f = open( 'dr.txt', 'w' )\n",
        "    for item in lr:\n",
        "      f.write(\"%s\\n\" % str(item))\n",
        "    f.close()\n",
        "\n",
        "    f = open( 'dx.txt', 'w' )\n",
        "    for item in lx:\n",
        "      f.write(\"%s\\n\" % str(item))\n",
        "    f.close()\n",
        "\n",
        "    f = open( 'dy.txt', 'w' )\n",
        "    for item in ly:\n",
        "      f.write(\"%s\\n\" % str(item))\n",
        "    f.close()\n",
        "\n",
        "    return correct/total, dr, dx, dy\n",
        "\n",
        "\n",
        "\n",
        "def val_std(model, dataloader, device, part, mean_dr ,mean_dx ,mean_dy ,prec=10):\n",
        "    l = len(dataloader)*part*b_s\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    mean = 0\n",
        "    meanx = 0\n",
        "    meany = 0\n",
        "    total=0\n",
        "    total_mean = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "          images = images.type(torch.FloatTensor)\n",
        "          pred = model(images.to(device))\n",
        "          pred = pred.to('cpu')\n",
        "          pred = torch.reshape(pred, (-1,  targets.size(2),  targets.size(2)))\n",
        "          for i in range((pred.size(0))):\n",
        "              pred_i_out, pred_j_out = get_max(pred[i],alpha=0.5,size=3, prec=prec)\n",
        "              c = np.vstack((pred_i_out, pred_j_out)).T\n",
        "              targ_i_out, targ_j_out = get_max(targets[i],alpha=0.5,size=3, prec=prec)\n",
        "              d = np.vstack((targ_i_out, targ_j_out)).T\n",
        "              total += len(d)\n",
        "              if prec!=10: print(\"1pix\")\n",
        "              dr, dx, dy, num = get_mean(c,d, prec)\n",
        "              sum= (dr/prec-mean_dr)*(dr/prec-mean_dr)\n",
        "              mean +=sum\n",
        "              sumx= (dx/prec-mean_dx)*(dx/prec-mean_dx)\n",
        "              meanx +=sumx\n",
        "              sumy= (dy/prec-mean_dy)*(dy/prec-mean_dy)\n",
        "              meany +=sumy\n",
        "              total_mean+=num\n",
        "              if total > l: \n",
        "                  break\n",
        "          if total > l: \n",
        "              break\n",
        "    dr = mean/total_mean\n",
        "    dx = meanx/total_mean\n",
        "    dy = meany/total_mean\n",
        "    return (dr)**0.5, (dx)**0.5, (dy)**0.5, total_mean\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJPCtzYCI7hm"
      },
      "source": [
        "net = torch.load('drive/MyDrive/Star_SuperRes/Last_Mask_old50_0.5761')\n",
        "#net = torch.load('drive/MyDrive/Star_SuperRes/Last_Mask_old50_1pix0.5683')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHZlWMHmBpij"
      },
      "source": [
        "prec =10\n",
        "test_set.prec=1\n",
        "accuracy_test , error_test , error_x, error_y= validate(net,test_loader,device, 1, prec =prec)\n",
        "print(\"Accuracy \", round(accuracy_test*100, 2), \"%\")\n",
        "\n",
        "std_test , std_x, std_y, total= val_std(net,test_loader,device, 1, error_test,error_x, error_y, \n",
        "                                 prec =prec )\n",
        "st = 3.291\n",
        "eps_test, eps_x, eps_y = std_test/(total-1)*st , std_x/(total-1)*st, std_y/(total-1)*st\n",
        "print()\n",
        "print(\"Error \", round(error_test, 2), \"pix\")\n",
        "print(\"Eps \", round(eps_test, 2), \"pix\")\n",
        "print(\"STD \", round(std_test, 2), \"pix\")\n",
        "print()\n",
        "print(\"ErrorX \", round(error_x, 2), \"pix\")\n",
        "print(\"Eps \", round(eps_x, 2), \"pix\")\n",
        "print(\"STDX \", round(std_x, 2), \"pix\")\n",
        "print()\n",
        "print(\"ErrorY \", round(error_y, 2), \"pix\")\n",
        "print(\"Eps \", round(eps_y, 2), \"pix\")\n",
        "print(\"STDY \", round(std_y, 2), \"pix\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}